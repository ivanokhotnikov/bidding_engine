{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidding engine development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "- [Imports](#imports)\n",
    "    - [Libraries](#libraries)\n",
    "    - [Raw data](#raw-data)\n",
    "- [Processing](#processing)\n",
    "    - [Missing values](#missing-values)\n",
    "        - [Filling with forward fill](#filling-with-forward-fill)\n",
    "        - [Filling with most frequent](#filling-with-most-frequent)\n",
    "        - [Filling with nearest neighbors](#filling-with-neighbours)\n",
    "    - [Converting object features to numerical](#converting-object-features-to-numerical)\n",
    "    - [Scaling metrics features](#scaling-metrics-features)\n",
    "    - [Downcasting numerical features](#downcasting-numerical-features)\n",
    "    - [Dummy variable for broad match modifier](#dummy-variable-for-broad-match-modifier)\n",
    "    - [Profiling interim data](#timeseries-of-the-random-feature-for-the-random-keyword)\n",
    "    - [Convert CPC to GBP](#convert-cpc-to-gbp)\n",
    "- [Quick look into keywords](#quick-look-into-keywords)\n",
    "    - [Most sessions](#most-sessions)\n",
    "    - [Least sessions](#least-sessions)\n",
    "    - [Most impressions](#most-impressions)\n",
    "    - [Least impressions](#least-impressions)\n",
    "- [Processed data](#processed-data)\n",
    "- [Keyword clustering](#keyword-clustering)\n",
    "    - [Embedding](#embedding)\n",
    "    - [k-means clustering](#k-means-clustering)\n",
    "    - [Agglomerative clustering](#agglomerative-clustering)\n",
    "- [Topic extraction](#topic-extraction)\n",
    "- [Work in progress](#work-in-progress)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "SEED = 10\n",
    "np.random.seed(seed=SEED)\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_feather(\n",
    "    os.path.join(os.environ['RAW_DATA_PATH'], 'bidding_data.feather'))\n",
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(raw_df.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.describe().T.style.background_gradient()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations\n",
    "\n",
    "1. 39 (out of 587,593) NaNs in `Cost` column. Nans rows can be dropped due to insignificant amount. Alternatively, can interpolated (forward fill) or imputed.\n",
    "\n",
    "2. The following columns could be converted to numerical (floats) judging by the `.head()` and columns names\n",
    "```\n",
    "8   AbsoluteTopImpressionPercentage   587593 non-null  object        \n",
    "9   TopImpressionPercentage           587593 non-null  object        \n",
    "10  SearchImpressionShare             587593 non-null  object        \n",
    "11  SearchTopImpressionShare          587593 non-null  object        \n",
    "12  SearchRankLostTopImpressionShare  587593 non-null  object        \n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing\n",
    "[top](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_df = raw_df.copy(deep=True)\n",
    "interim_df_sorted = interim_df.sort_values(\n",
    "    by=['CriterionId', 'Date']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_keyword(df, criterion, features):\n",
    "    '''\n",
    "    The plot_keyword function takes a dataframe, criterion ID, and list of features to plot.\n",
    "    It then plots the specified features for the given criterion ID.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        df\n",
    "            Pass the dataframe to the function\n",
    "        criterion\n",
    "            Select the keyword to plot\n",
    "        features\n",
    "            Specify which columns to plot\n",
    "    '''\n",
    "    for feature in features:\n",
    "        plt.plot(df.loc[df['CriterionId'] == criterion, 'Date'],\n",
    "                 df.loc[df['CriterionId'] == criterion, feature],\n",
    "                 label=feature)\n",
    "    plt.title('Keyword ID {}\\nUnique keywords {}'.format(\n",
    "        criterion, raw_df.loc[raw_df['CriterionId'] == criterion,\n",
    "                              'Criteria'].unique()))\n",
    "    plt.xticks(rotation=45)\n",
    "    if len(features) == 1:\n",
    "        plt.ylabel(feature)\n",
    "    else:\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filled(df, criterion, features):\n",
    "    '''\n",
    "    The plot_filled function takes a dataframe, criterion ID, and list of features as input.\n",
    "    It then plots the filled values for each feature in the list against the date.\n",
    "    If there is only one feature in the list, it labels that axis with that feature name.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        df\n",
    "            Pass the dataframe to the function\n",
    "        criterion\n",
    "            Filter the dataframe to only show the rows that have a criterionid equal to criterion\n",
    "        features\n",
    "            Specify which columns to plot\n",
    "    '''\n",
    "    from matplotlib.markers import MarkerStyle\n",
    "\n",
    "    markers = list(MarkerStyle.markers.keys())[1:len(features) + 1]\n",
    "    plt.figure()\n",
    "    for feature, marker in zip(features, markers):\n",
    "        if 'filled' in feature:\n",
    "            plt.plot(df.loc[(df['CriterionId'] == criterion)\n",
    "                            & (df['Cost'].isna()), 'Date'],\n",
    "                     df.loc[(df['CriterionId'] == criterion) &\n",
    "                            (df['Cost'].isna()), feature],\n",
    "                     marker,\n",
    "                     label=feature)\n",
    "        else:\n",
    "            plt.plot(df.loc[df['CriterionId'] == criterion, 'Date'],\n",
    "                     df.loc[df['CriterionId'] == criterion, feature],\n",
    "                     label=feature)\n",
    "    plt.title('Keyword ID {}\\nUnique keywords {}'.format(\n",
    "        criterion,\n",
    "        df.sort_values(\n",
    "            by=['CriterionId', 'Date']).loc[df['CriterionId'] == criterion,\n",
    "                                            'Criteria'].unique()))\n",
    "    plt.xticks(rotation=45)\n",
    "    if len(features) == 1:\n",
    "        plt.ylabel(feature)\n",
    "    else:\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_criterionids = raw_df.loc[raw_df['Cost'].isnull(),\n",
    "                                  'CriterionId'].unique()\n",
    "print(f'unique keywords with missing values: {len(missing_criterionids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_criterion_with_missing_cost = np.random.choice(missing_criterionids)\n",
    "# features = ['Cost']\n",
    "# plot_keyword(df=interim_df_sorted,\n",
    "#              criterion=random_criterion_with_missing_cost,\n",
    "#              features=features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling with forward fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interim_df_sorted['Cost_forward_filled'] = interim_df_sorted[\n",
    "#     'Cost'].interpolate(method='ffill')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling with most frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "frequency_imp = SimpleImputer(strategy='most_frequent')\n",
    "interim_df_sorted['Cost_frequency_filled'] = interim_df_sorted['Cost'].copy(\n",
    "    deep=True)\n",
    "for criterion in missing_criterionids:\n",
    "    interim_df_sorted.loc[\n",
    "        interim_df_sorted['CriterionId'] == criterion,\n",
    "        'Cost_frequency_filled'] = frequency_imp.fit_transform(\n",
    "            interim_df_sorted.loc[\n",
    "                interim_df_sorted['CriterionId'] == criterion,\n",
    "                'Cost_frequency_filled'].values.reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interim_df_sorted['Cost_mode_filled'] = interim_df_sorted['Cost'].copy(\n",
    "#     deep=True)\n",
    "# modes = []\n",
    "# for criterion in missing_criterionids:\n",
    "#     mode = interim_df_sorted.loc[interim_df_sorted['CriterionId'] == criterion,\n",
    "#                                  'Cost_mode_filled'].mode().values[0]\n",
    "#     interim_df_sorted.loc[interim_df_sorted['CriterionId'] == criterion,\n",
    "#                           'Cost_mode_filled'] = interim_df_sorted.loc[\n",
    "#                               interim_df_sorted['CriterionId'] == criterion,\n",
    "#                               'Cost_mode_filled'].fillna(value=mode)\n",
    "#     modes.append(mode)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling with neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.impute import KNNImputer\n",
    "\n",
    "# knn_imp = KNNImputer(n_neighbors=5, weights='distance')\n",
    "# interim_df_sorted['Cost_knn_filled'] = interim_df_sorted['Cost'].copy(\n",
    "#     deep=True)\n",
    "# for criterion in missing_criterionids:\n",
    "#     interim_df_sorted.loc[\n",
    "#         interim_df_sorted['CriterionId'] == criterion,\n",
    "#         'Cost_knn_filled'] = knn_imp.fit_transform(interim_df_sorted.loc[\n",
    "#             interim_df_sorted['CriterionId'] == criterion,\n",
    "#             'Cost_knn_filled'].values.reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of the filling methods on the random keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filled = interim_df_sorted.loc[interim_df_sorted['Cost'].isna(), [\n",
    "#     'Cost', 'Cost_knn_filled', 'Cost_forward_filled', 'Cost_frequency_filled',\n",
    "#     'Cost_mode_filled'\n",
    "# ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_filled(\n",
    "#     df=interim_df_sorted,\n",
    "#     #   uncomment to see filling on a random keyword\n",
    "#     # criterion=np.random.choice(missing_criterionids),\n",
    "#     #   uncomment below to see filing on the same keyword as above\n",
    "#     criterion=random_criterion_with_missing_cost,\n",
    "#     features=[\n",
    "#         'Cost', 'Cost_forward_filled', 'Cost_frequency_filled',\n",
    "#         'Cost_knn_filled', 'Cost_mode_filled'\n",
    "#     ])\n",
    "# print('keyword {}. mode: {}'.format(\n",
    "#     criterion,\n",
    "#     interim_df_sorted.loc[interim_df_sorted['CriterionId'] == criterion,\n",
    "#                           'Cost'].mode()[0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion on filling NaNs\n",
    "\n",
    "Due to sparsity of the data, filling with the most frequent (mode) per keyword value was chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_df_sorted_no_nans = interim_df_sorted.copy(deep=True)\n",
    "interim_df_sorted_no_nans['Cost'] = interim_df_sorted_no_nans[\n",
    "    'Cost_frequency_filled']\n",
    "interim_df_sorted_no_nans.drop(\n",
    "    columns=[\n",
    "        # 'Cost_forward_filled',\n",
    "        'Cost_frequency_filled',\n",
    "        # 'Cost_knn_filled',\n",
    "        # 'Cost_mode_filled',\n",
    "    ],\n",
    "    inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting object features to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = [\n",
    "    'AbsoluteTopImpressionPercentage', 'TopImpressionPercentage',\n",
    "    'SearchImpressionShare', 'SearchTopImpressionShare',\n",
    "    'SearchRankLostTopImpressionShare'\n",
    "]\n",
    "\n",
    "for col in object_columns:\n",
    "    interim_df_sorted_no_nans[col] = interim_df_sorted_no_nans[col].str.lstrip(\n",
    "        '<').str.rstrip('%').astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling metrics features\n",
    "\n",
    "See the ranges of metrics in [Google Ad API](https://developers.google.com/google-ads/api/fields/v11/metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in object_columns:\n",
    "    interim_df_sorted_no_nans[col] = (interim_df_sorted_no_nans[col] -\n",
    "                                      interim_df_sorted_no_nans[col].min()\n",
    "                                      ) / interim_df_sorted_no_nans[col].max()\n",
    "    if 'Percentage' in col:\n",
    "        interim_df_sorted_no_nans[col] *= 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downcasting numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcols = interim_df_sorted_no_nans.select_dtypes('float').columns\n",
    "icols = interim_df_sorted_no_nans.select_dtypes('integer').columns\n",
    "\n",
    "interim_df_sorted_no_nans[fcols] = interim_df_sorted_no_nans[fcols].apply(\n",
    "    pd.to_numeric, downcast='float')\n",
    "interim_df_sorted_no_nans[icols] = interim_df_sorted_no_nans[icols].apply(\n",
    "    pd.to_numeric, downcast='integer')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy variable for broad match modifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same index, AdGroupName can contain BMM in the name, but Criteria may not include it. '+' in Criteria is prevailing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_df_sorted_no_nans['BMM'] = interim_df_sorted_no_nans[\n",
    "    'Criteria'].str.contains('+', regex=False).astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_df_sorted_no_nans[\n",
    "    interim_df_sorted_no_nans['AdGroupName'].str.contains('BMM')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_df_sorted_no_nans[interim_df_sorted_no_nans['Criteria'].str.contains(\n",
    "    '+', regex=False)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Replacing non alphanum in keywords -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all(interim_df_sorted_no_nans['Criteria'].str.islower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interim_df_sorted_no_nans['Criteria'] = interim_df_sorted_no_nans[\n",
    "#     'Criteria'].str.replace(r'[^\\w\\s]+', '', regex=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling interim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'interim_data.html' not in os.listdir(os.environ['DATA_PROFILES_PATH']):\n",
    "    from ydata_profiling import ProfileReport\n",
    "\n",
    "    os.makedirs(os.environ['DATA_PROFILES_PATH'], exist_ok=True)\n",
    "    interim_data_profile = ProfileReport(interim_df_sorted_no_nans,\n",
    "                                         title='Interim Data Profile')\n",
    "    interim_data_profile.to_file(\n",
    "        os.path.join(os.environ['DATA_PROFILES_PATH'], 'interim_data.html'))\n",
    "    del interim_data_profile\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Add ROI -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interim_df_sorted_no_nans['ROI_gbp'] = interim_df_sorted_no_nans[\n",
    "#     'Margin'].divide(interim_df_sorted_no_nans['Cost_gbp'],\n",
    "#                      fill_value=0).replace({\n",
    "#                          np.inf: 0,\n",
    "#                          np.nan: 0\n",
    "#                      })\n",
    "# interim_df_sorted_no_nans['ROI'] = interim_df_sorted_no_nans['Margin'].divide(\n",
    "#     interim_df_sorted_no_nans['Cost'], fill_value=0).replace({\n",
    "#         np.inf: 0,\n",
    "#         np.nan: 0\n",
    "#     })\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert CPC to GBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micros_to_gbp = interim_df_sorted_no_nans['Cost'].div(\n",
    "    interim_df_sorted_no_nans['Cost_gbp']).replace({\n",
    "        np.nan: 0,\n",
    "        np.inf: 0\n",
    "    }).unique()[1:].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_df_sorted_no_nans[\n",
    "    'CpcBid_gbp'] = interim_df_sorted_no_nans['CpcBid'] / micros_to_gbp\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick look into keywords\n",
    "[top](#contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique keyword ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(interim_df_sorted_no_nans['CriterionId'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique keyword ids with positive sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(interim_df_sorted_no_nans.loc[(interim_df_sorted_no_nans['Margin'] > 0) &\n",
    "                                  (interim_df_sorted_no_nans['Sessions'] > 0),\n",
    "                                  'CriterionId'].unique())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative_margins = interim_df_sorted_no_nans.loc[\n",
    "#     interim_df_sorted_no_nans['Margin'] < 0, 'CriterionId'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for criterion in negative_margins:\n",
    "#     plot_keyword(df=interim_df_sorted_no_nans,\n",
    "#                  criterion=criterion,\n",
    "#                  features=['Sessions', 'Cost_gbp'])\n",
    "#     print('Negative margins: {} at {}'.format(interim_df_sorted_no_nans.loc[\n",
    "#         (interim_df_sorted_no_nans['CriterionId'] == criterion) &\n",
    "#         (interim_df_sorted_no_nans['Margin'] < 0), 'Margin'].values, interim_df_sorted_no_nans.loc[\n",
    "#         (interim_df_sorted_no_nans['CriterionId'] == criterion) &\n",
    "#         (interim_df_sorted_no_nans['Margin'] < 0), 'Date'].dt.date))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this context, the negative margins are unlikely to mean loss. Apply abs() to margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_df_sorted_no_nans['Margin'] = abs(interim_df_sorted_no_nans['Margin'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_sessions = interim_df_sorted_no_nans.sort_values(\n",
    "    by=['Sessions'],\n",
    "    ascending=False).loc[interim_df_sorted_no_nans['Margin'] > 0,\n",
    "                         'CriterionId'][:75].unique()\n",
    "print(most_sessions)\n",
    "interim_df_sorted_no_nans.loc[\n",
    "    interim_df_sorted_no_nans['CriterionId'].isin(most_sessions),\n",
    "    'Criteria'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_sessions = interim_df_sorted_no_nans.sort_values(\n",
    "    by=['Sessions'], ascending=True)['CriterionId'].unique()[:10]\n",
    "print(least_sessions)\n",
    "interim_df_sorted_no_nans.loc[\n",
    "    interim_df_sorted_no_nans['CriterionId'].isin(least_sessions),\n",
    "    'Criteria'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_impressions = interim_df_sorted_no_nans.sort_values(\n",
    "    by=['Impressions'], ascending=False)['CriterionId'].unique()[:10]\n",
    "print(most_impressions)\n",
    "interim_df_sorted_no_nans.loc[\n",
    "    interim_df_sorted_no_nans['CriterionId'].isin(most_impressions),\n",
    "    'Criteria'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_impressions = interim_df_sorted_no_nans.sort_values(\n",
    "    by=['Impressions'], ascending=True)['CriterionId'].unique()[:10]\n",
    "print(least_impressions)\n",
    "interim_df_sorted_no_nans.loc[\n",
    "    interim_df_sorted_no_nans['CriterionId'].isin(least_impressions),\n",
    "    'Criteria'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processed data\n",
    "[top](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = interim_df_sorted_no_nans.copy(deep=True)\n",
    "fcols = processed_df.select_dtypes('float').drop(\n",
    "    columns=['Cost', 'CpcBid']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = processed_df[\n",
    "    ['CriterionId', 'Criteria', 'Date', 'Impressions', 'BMM'] + fcols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.describe().T.style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'processed_data.html' not in os.listdir(os.environ['DATA_PROFILES_PATH']):\n",
    "    from ydata_profiling import ProfileReport\n",
    "\n",
    "    os.makedirs(os.environ['DATA_PROFILES_PATH'], exist_ok=True)\n",
    "    processed_data_profile = ProfileReport(processed_df,\n",
    "                                           title='Processed Data Profile')\n",
    "    processed_data_profile.to_file(\n",
    "        os.path.join(os.environ['DATA_PROFILES_PATH'], 'processed_data.html'))\n",
    "    del processed_data_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Criteria_bmm_ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['Criteria_bmm_ignored'] = processed_df['Criteria'].str.replace(\n",
    "    r'[^\\w\\s]+', '', regex=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword clustering\n",
    "[top](#contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw_df, interim_df_sorted_no_nans, interim_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwds = processed_df['Criteria'].unique()\n",
    "print(len(kwds))\n",
    "kwds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwds_no_bmm = processed_df['Criteria'].str.replace(r'[^\\w\\s]+', '',\n",
    "                                                   regex=True).unique()\n",
    "print(len(kwds_no_bmm))\n",
    "kwds_no_bmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwds_embeddings = model.encode(kwds_no_bmm)\n",
    "kwds_embeddings.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(clusters, return_clustered=False):\n",
    "    clustered = {}\n",
    "    for i, cluster_id in enumerate(clusters):\n",
    "        if cluster_id not in clustered:\n",
    "            clustered[cluster_id] = []\n",
    "        clustered[cluster_id].append(kwds_no_bmm[i])\n",
    "\n",
    "    for i, kw in sorted(clustered.items()):\n",
    "        print('Cluster {}, {} elements\\n{}\\n'.format(i + 1, len(kw), kw))\n",
    "\n",
    "    if return_clustered:\n",
    "        return clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "n_clusters = 5\n",
    "kmeans_model = KMeans(n_clusters=n_clusters,\n",
    "                      max_iter=500,\n",
    "                      n_init=100,\n",
    "                      init='k-means++',\n",
    "                      random_state=SEED)\n",
    "kmeans_model.fit(normalize(kwds_embeddings))\n",
    "kmeans_clusters = kmeans_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clusters(kmeans_clusters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "agglomerative_model = AgglomerativeClustering(n_clusters=None,\n",
    "                                              metric='cosine',\n",
    "                                              linkage='complete',\n",
    "                                              distance_threshold=0.9)\n",
    "agglomerative_model.fit(kwds_embeddings)\n",
    "agglo_clusters = agglomerative_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered = get_clusters(agglo_clusters, return_clustered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['Agglomerated_cluster'] = processed_df[\n",
    "    'Criteria_bmm_ignored'].map(\n",
    "        lambda x: [k for k, v in clustered.items() if x in v][0])\n",
    "processed_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['Agglomerated_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impressions_df = pd.DataFrame()\n",
    "for cluster in set(agglo_clusters):\n",
    "    impressions_df[f'{cluster}'] = processed_df.loc[\n",
    "        processed_df['Agglomerated_cluster'] == cluster,\n",
    "        ['Impressions', 'Date']].groupby(by='Date').sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impressions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in impressions_df.columns:\n",
    "    plt.plot(impressions_df.loc[:,col])\n",
    "    plt.xticks(rotation=45)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bertopic import BERTopic\n",
    "\n",
    "# topic_model = BERTopic(min_topic_size=50, top_n_words=5)\n",
    "# topics, probs = topic_model.fit_transform(kwds_no_bmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_topics = topic_model.get_topics()\n",
    "# all_topics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise clusters with PCA\n",
    "Following the [sklearn example](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html#sphx-glr-auto-examples-cluster-plot-kmeans-digits-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# reduced_data = PCA(n_components=2).fit_transform(kwds_embeddings)\n",
    "# kmeans_model_reduced = KMeans(n_clusters=n_clusters,\n",
    "#                               max_iter=500,\n",
    "#                               n_init=100,\n",
    "#                               init='k-means++',\n",
    "#                               random_state=SEED)\n",
    "# kmeans_model_reduced.fit(reduced_data)\n",
    "\n",
    "# h = 0.02\n",
    "# x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "# y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "# xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "# Z = kmeans_model_reduced.predict(np.c_[xx.ravel(),\n",
    "#                                        yy.ravel()].astype(np.float32))\n",
    "# Z = Z.reshape(xx.shape)\n",
    "# centroids = kmeans_model_reduced.cluster_centers_\n",
    "# plt.imshow(Z,\n",
    "#            interpolation='nearest',\n",
    "#            extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "#            cmap=plt.cm.Pastel2)\n",
    "# plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
    "# plt.scatter(centroids[:, 0],\n",
    "#             centroids[:, 1],\n",
    "#             marker='x',\n",
    "#             s=169,\n",
    "#             linewidths=3,\n",
    "#             color='w',\n",
    "#             zorder=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import umap\n",
    "# umap_embeddings = umap.UMAP(n_neighbors=15,\n",
    "#                             n_components=5,\n",
    "#                             metric='cosine').fit_transform(kwds_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hdbscan\n",
    "# cluster = hdbscan.HDBSCAN(min_cluster_size=15,\n",
    "#                           metric='euclidean',\n",
    "#                           cluster_selection_method='eom').fit(umap_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Prepare data\n",
    "# umap_data = umap.UMAP(n_neighbors=15, n_components=2, min_dist=0.0, metric='cosine').fit_transform(kwds_embeddings)\n",
    "# result = pd.DataFrame(umap_data, columns=['x', 'y'])\n",
    "# result['labels'] = cluster.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize clusters\n",
    "# fig, ax = plt.subplots()\n",
    "# outliers = result.loc[result.labels == -1, :]\n",
    "# clustered = result.loc[result.labels != -1, :]\n",
    "# plt.scatter(outliers.x, outliers.y, color='#BDBDBD')\n",
    "# plt.scatter(clustered.x, clustered.y, c=clustered.labels,cmap='viridis_r')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim.downloader as api\n",
    "\n",
    "# glove = api.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_df['Criteria_tokens'] = processed_df['Criteria'].map(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length = processed_df['Criteria_tokens'].map(lambda x: len(x)).unique().max()\n",
    "# max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_glove = []\n",
    "# for kw in processed_df['Criteria'].unique():\n",
    "#     for ikw in kw.split():\n",
    "#         in_glove.append(ikw in glove.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x.split() for x in processed_df['Criteria'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(glove.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_df['in_glove'] = processed_df['Criteria_tokens'].map(\n",
    "#     lambda x: all([True for xi in x if xi in glove.index_to_key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_df['in_glove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all([xi in glove.index_to_key for xi in [x.split() for x in processed_df['Criteria'].unique()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_df['Criteria_tokens'].map(\n",
    "#     lambda x: all([True for xi in x if xi in glove.index_to_key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = []\n",
    "# embeddings = {}\n",
    "# with open(os.path.join(os.environ['GLOVE_PATH'], 'glove.6B.50d.txt'),\n",
    "#           'rt',\n",
    "#           encoding='utf-8') as f:\n",
    "#     for line in f:\n",
    "#         values = line.split()\n",
    "#         word = values[0]\n",
    "#         vocab.append(word)\n",
    "#         vector = np.asarray(values[1:], 'float32')\n",
    "#         embeddings[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interim_df['Criteria_tokens'] = interim_df['Criteria'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interim_df['Criteria_tokens'] = interim_df['Criteria'].map(\n",
    "#     lambda x: tokenizer.tokenize(x, padding='max_length', truncation=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interim_df['Criteria_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interim_df['Criteria_ids'] = interim_df['Criteria_tokens'].map(\n",
    "#     lambda x: tokenizer.convert_tokens_to_ids(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interim_df['Criteria_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import DistilBertModel\n",
    "\n",
    "# model = DistilBertModel.from_pretrained('distilbert-base-uncased',\n",
    "#                                         output_hidden_states=True)\n",
    "# model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
