{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Forecating (Keras)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Forecating (Keras)](#toc1_)    \n",
    "  - [Create sequences](#toc1_1_)    \n",
    "  - [Split](#toc1_2_)    \n",
    "  - [Scale](#toc1_3_)    \n",
    "  - [Train](#toc1_4_)    \n",
    "  - [Features](#toc1_5_)    \n",
    "  - [Parameters](#toc1_6_)    \n",
    "  - [Evaluate](#toc1_7_)    \n",
    "- [Training](#toc2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "\n",
    "SEED = 10\n",
    "np.random.seed(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Create sequences](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df: pd.DataFrame, lookback: int, target: str,\n",
    "                     inference: bool, univariate: bool) -> tuple | np.ndarray:\n",
    "    x_train, y_train = [], []\n",
    "    if univariate:\n",
    "        for i in range(lookback, len(df)):\n",
    "            x_train.append(df.iloc[i - lookback:i][target])\n",
    "            y_train.append(df.iloc[i][target])\n",
    "        x_train = np.expand_dims(x_train, axis=-1)\n",
    "    else:\n",
    "        for i in range(lookback, len(df)):\n",
    "            x_train.append(df.iloc[i - lookback:i])\n",
    "            y_train.append(df.iloc[i][target])\n",
    "        x_train = np.stack(x_train)\n",
    "    y_train = np.expand_dims(y_train, axis=-1)\n",
    "    if inference:\n",
    "        return x_train\n",
    "    return x_train, y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Split](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df: pd.DataFrame, train_split: float) -> tuple:\n",
    "    interim_df = df.copy(deep=True)\n",
    "    train = interim_df.iloc[:int(len(interim_df) * train_split)]\n",
    "    test = interim_df.iloc[int(len(interim_df) * train_split):]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Scale](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(df: pd.DataFrame, timestamp: str, cluster: int,\n",
    "          test: bool) -> tuple | pd.DataFrame:\n",
    "    if not test:\n",
    "        scaler = StandardScaler()\n",
    "        scaled = scaler.fit_transform(df.values)\n",
    "        path = os.path.join(os.environ['RUNS_PATH'], timestamp,\n",
    "                            f'cluster_{cluster}')\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        joblib.dump(scaler, os.path.join(path, 'scaler.joblib'))\n",
    "    else:\n",
    "        scaler = joblib.load(\n",
    "            os.path.join(os.environ['MODELS_PATH'], 'scaler.joblib'))\n",
    "        scaled = scaler.transform(df.values)\n",
    "    scaled_df = pd.DataFrame(scaled, columns=df.columns)\n",
    "    # os.makedirs(processed_data_path, exist_ok=True)\n",
    "    # scaled_df.to_parquet(os.path.join(\n",
    "    #     processed_data_path,\n",
    "    #     f'scaled_{\"train\" if not test else \"test\"}.parquet'),\n",
    "    #                      index=False)\n",
    "    return scaler, scaled_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Train](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df: pd.DataFrame,\n",
    "          target: str,\n",
    "          folds: int,\n",
    "          lookback: int,\n",
    "          univariate: bool,\n",
    "          lstm_units: int,\n",
    "          learning_rate: float,\n",
    "          batch_size: int,\n",
    "          val_split: float,\n",
    "          epochs: int,\n",
    "          patience: int,\n",
    "          verbose: int,\n",
    "          cluster: int,\n",
    "          timestamp: str | None = None) -> tuple:\n",
    "    \"\"\"\n",
    "    The train function trains a model on the data provided.\n",
    "\n",
    "    Args:\n",
    "        df: pd.DataFrame: Pass the dataframe with all the features\n",
    "        target: str: Define the column name of the target variable\n",
    "        folds: int: Define the number of folds to be used in cross-validation\n",
    "        lookback: int: Define the number of time steps to look back in order to predict the next value\n",
    "        univariate: bool: Create the sequences for training and validation\n",
    "        lstm_units: int: Define the number of units in each lstm layer\n",
    "        learning_rate: float: Control the magnitude of the updates to weights during training\n",
    "        batch_size: int: Specify the number of samples to work through before updating the internal model parameters\n",
    "        val_split: float: Specify the fraction of the training data to be used as validation data\n",
    "        epochs: int: Specify the number of epochs to train for\n",
    "        patience: int: Stop the training early if the loss does not improve after a given number of epochs\n",
    "        verbose: int: Control the amount of logging information printed during training\n",
    "\n",
    "    Returns:\n",
    "        A tuple with two elements: model and val_metrics\n",
    "    \"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=folds)\n",
    "    val_loss, val_rmse = [], []\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(patience=patience,\n",
    "                                      monitor='val_loss',\n",
    "                                      mode='min',\n",
    "                                      verbose=verbose,\n",
    "                                      restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                          factor=0.75,\n",
    "                                          patience=patience // 2,\n",
    "                                          verbose=verbose,\n",
    "                                          mode='min')\n",
    "    ]\n",
    "    for fold, (train_index, val_index) in enumerate(tscv.split(df), start=1):\n",
    "        if timestamp is not None:\n",
    "            callbacks.append(\n",
    "                keras.callbacks.TensorBoard(log_dir=os.path.join(\n",
    "                    os.environ['RUNS_PATH'], timestamp, f'cluster_{cluster}',f'fold_{fold}'),\n",
    "                                            histogram_freq=1,\n",
    "                                            write_graph=True,\n",
    "                                            write_images=True,\n",
    "                                            update_freq='epoch'))\n",
    "        x_train, y_train = create_sequences(df=df.iloc[train_index],\n",
    "                                            lookback=lookback,\n",
    "                                            univariate=univariate,\n",
    "                                            target=target,\n",
    "                                            inference=False)\n",
    "        model = keras.models.Sequential(name='forecaster')\n",
    "        model.add(\n",
    "            keras.layers.LSTM(lstm_units,\n",
    "                              input_shape=(x_train.shape[1], x_train.shape[2]),\n",
    "                              return_sequences=False))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(\n",
    "            loss=keras.losses.mean_squared_error,\n",
    "            metrics=keras.metrics.RootMeanSquaredError(),\n",
    "            optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate))\n",
    "        history = model.fit(x_train,\n",
    "                            y_train,\n",
    "                            shuffle=False,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            validation_split=val_split,\n",
    "                            verbose=verbose,\n",
    "                            callbacks=callbacks)\n",
    "        x_val, y_val = create_sequences(df=df.iloc[val_index],\n",
    "                                        lookback=lookback,\n",
    "                                        univariate=univariate,\n",
    "                                        target=target,\n",
    "                                        inference=False)\n",
    "        val_loss_in_fold, val_rmse_in_fold = model.evaluate(\n",
    "            x=x_val, y=y_val, batch_size=batch_size, verbose=verbose)\n",
    "        val_loss.append(val_loss_in_fold)\n",
    "        val_rmse.append(val_rmse_in_fold)\n",
    "    val_metrics = {\n",
    "        'val_loss_mean': np.mean(val_loss),\n",
    "        'val_loss_std': np.std(val_loss),\n",
    "        'val_rmse_mean': np.mean(val_rmse),\n",
    "        'val_rmse_std': np.std(val_rmse)\n",
    "    }\n",
    "    return model, val_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Features](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'Impressions',\n",
    "    'AbsoluteTopImpressionPercentage',\n",
    "    'TopImpressionPercentage',\n",
    "    'SearchImpressionShare',\n",
    "    'SearchTopImpressionShare',\n",
    "    'SearchRankLostTopImpressionShare',\n",
    "    'Clicks',\n",
    "    'Cost_gbp',\n",
    "    'CpcBid_gbp',\n",
    "]\n",
    "features_date = features + ['Date']\n",
    "target = 'CpcBid_gbp'\n",
    "features.remove(target)\n",
    "with open(\n",
    "        os.path.join(os.environ['MODELS_PATH'], 'kmeans_clustered_dict.json'),\n",
    "        'r') as f:\n",
    "    clustered = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Parameters](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 14\n",
    "pred_len = 1\n",
    "features = features\n",
    "target = target\n",
    "train_split = 0.8\n",
    "test_split = 0.2\n",
    "batch_size = 4\n",
    "patience = 20\n",
    "epochs = 500\n",
    "learning_rate = 0.01\n",
    "log_interval = 10\n",
    "seed = SEED\n",
    "hidden_size = 10\n",
    "num_layers = 2\n",
    "folds = 5\n",
    "univariate = False\n",
    "lstm_units = 10\n",
    "val_split = .1\n",
    "verbose = 10\n",
    "timestamp = datetime.now().strftime('%Y%m%d%H%M%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_7_'></a>[Evaluate](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df: pd.DataFrame, model: keras.models.Model, lookback: int,\n",
    "             batch_size: int, univariate: bool, target: str,\n",
    "             verbose: int) -> dict:\n",
    "    \"\"\"\n",
    "    The evaluate function evaluates the model on the test data.\n",
    "    It returns a dictionary with two keys: `test_loss` and `test_rmse`.\n",
    "    The values of each key are scalar values that give the loss and RMSE on\n",
    "    the test set, respectively.\n",
    "\n",
    "    Args:\n",
    "        df: pd.DataFrame: Pass the dataframe that is used for training and testing\n",
    "        model: keras.models.Model: Evaluate the model\n",
    "        lookback: int: Define how many timesteps back the input data should go\n",
    "        batch_size: int: Define the number of samples per gradient update\n",
    "        univariate: bool: Determine whether the model is univariate or multivariate\n",
    "        target: str: Specify the column name of the target variable\n",
    "        verbose: int: Specify the verbosity of the model\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with two values: test_loss, test_rmse\n",
    "    \"\"\"\n",
    "    x_test, y_test = create_sequences(df=df,\n",
    "                                      lookback=lookback,\n",
    "                                      univariate=univariate,\n",
    "                                      target=target,\n",
    "                                      inference=False)\n",
    "    test_loss, test_rmse = model.evaluate(x=x_test,\n",
    "                                          y=y_test,\n",
    "                                          batch_size=batch_size,\n",
    "                                          verbose=verbose)\n",
    "    return {'test_loss': test_loss, 'test_rmse': test_rmse}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Training](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "Epoch 41/500\n",
      "Epoch 42/500\n",
      "Epoch 43/500\n",
      "Epoch 44/500\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
      "Epoch 44: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "Epoch 41/500\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
      "Epoch 41: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "Epoch 41/500\n",
      "Epoch 42/500\n",
      "Epoch 43/500\n",
      "Epoch 44/500\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
      "Epoch 44: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
      "Epoch 32: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 32: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "Epoch 41/500\n",
      "Epoch 42/500\n",
      "Epoch 43/500\n",
      "Epoch 44/500\n",
      "Epoch 45/500\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 46/500\n",
      "Epoch 47/500\n",
      "Epoch 48/500\n",
      "Epoch 49/500\n",
      "Epoch 50/500\n",
      "Epoch 51/500\n",
      "Epoch 52/500\n",
      "Epoch 53/500\n",
      "Epoch 54/500\n",
      "Epoch 55/500\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
      "Epoch 55: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "Epoch 41/500\n",
      "Epoch 42/500\n",
      "Epoch 43/500\n",
      "Epoch 44/500\n",
      "Epoch 45/500\n",
      "Epoch 46/500\n",
      "Epoch 47/500\n",
      "Epoch 48/500\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 49/500\n",
      "Epoch 50/500\n",
      "Epoch 51/500\n",
      "Epoch 52/500\n",
      "Epoch 53/500\n",
      "Epoch 54/500\n",
      "Epoch 55/500\n",
      "Epoch 56/500\n",
      "Epoch 57/500\n",
      "Epoch 58/500\n",
      "Epoch 59/500\n",
      "Epoch 60/500\n",
      "Epoch 61/500\n",
      "Epoch 62/500\n",
      "Epoch 63/500\n",
      "Epoch 64/500\n",
      "Epoch 65/500\n",
      "Epoch 66/500\n",
      "Epoch 67/500\n",
      "Epoch 68/500\n",
      "Epoch 69/500\n",
      "Epoch 70/500\n",
      "Epoch 71/500\n",
      "Epoch 72/500\n",
      "Epoch 73/500\n",
      "Epoch 74/500\n",
      "Epoch 75/500\n",
      "Epoch 76/500\n",
      "Epoch 77/500\n",
      "Epoch 78/500\n",
      "Epoch 79/500\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 80/500\n",
      "Epoch 81/500\n",
      "Epoch 82/500\n",
      "Epoch 83/500\n",
      "Epoch 84/500\n",
      "Epoch 85/500\n",
      "Epoch 86/500\n",
      "Epoch 87/500\n",
      "Epoch 88/500\n",
      "Epoch 89/500\n",
      "Epoch 90/500\n",
      "Epoch 91/500\n",
      "Epoch 92/500\n",
      "Epoch 93/500\n",
      "Epoch 94/500\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
      "Epoch 95/500\n",
      "Epoch 96/500\n",
      "Epoch 97/500\n",
      "Epoch 98/500\n",
      "Epoch 99/500\n",
      "Epoch 100/500\n",
      "Epoch 101/500\n",
      "Epoch 102/500\n",
      "Epoch 103/500\n",
      "Epoch 104/500\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.003164062276482582.\n",
      "Epoch 104: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "Epoch 41/500\n",
      "Epoch 42/500\n",
      "Epoch 43/500\n",
      "Epoch 44/500\n",
      "Epoch 45/500\n",
      "Epoch 46/500\n",
      "Epoch 47/500\n",
      "Epoch 48/500\n",
      "Epoch 49/500\n",
      "Epoch 50/500\n",
      "Epoch 51/500\n",
      "Epoch 52/500\n",
      "Epoch 53/500\n",
      "Epoch 54/500\n",
      "Epoch 55/500\n",
      "Epoch 56/500\n",
      "Epoch 57/500\n",
      "Epoch 58/500\n",
      "Epoch 59/500\n",
      "Epoch 60/500\n",
      "Epoch 61/500\n",
      "Epoch 62/500\n",
      "Epoch 63/500\n",
      "Epoch 64/500\n",
      "Epoch 65/500\n",
      "Epoch 66/500\n",
      "Epoch 67/500\n",
      "Epoch 68/500\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 69/500\n",
      "Epoch 70/500\n",
      "Epoch 71/500\n",
      "Epoch 72/500\n",
      "Epoch 73/500\n",
      "Epoch 74/500\n",
      "Epoch 75/500\n",
      "Epoch 76/500\n",
      "Epoch 77/500\n",
      "Epoch 78/500\n",
      "Epoch 79/500\n",
      "Epoch 80/500\n",
      "Epoch 81/500\n",
      "Epoch 82/500\n",
      "Epoch 83/500\n",
      "Epoch 84/500\n",
      "Epoch 85/500\n",
      "Epoch 86/500\n",
      "Epoch 87/500\n",
      "Epoch 88/500\n",
      "Epoch 89/500\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 90/500\n",
      "Epoch 91/500\n",
      "Epoch 92/500\n",
      "Epoch 93/500\n",
      "Epoch 94/500\n",
      "Epoch 95/500\n",
      "Epoch 96/500\n",
      "Epoch 97/500\n",
      "Epoch 98/500\n",
      "Epoch 99/500\n",
      "Epoch 100/500\n",
      "Epoch 101/500\n",
      "Epoch 102/500\n",
      "Epoch 103/500\n",
      "Epoch 104/500\n",
      "Epoch 105/500\n",
      "Epoch 106/500\n",
      "Epoch 107/500\n",
      "Epoch 108/500\n",
      "Epoch 109/500\n",
      "Epoch 110/500\n",
      "Epoch 111/500\n",
      "Epoch 112/500\n",
      "Epoch 113/500\n",
      "Epoch 114/500\n",
      "Epoch 115/500\n",
      "Epoch 116/500\n",
      "Epoch 117/500\n",
      "Epoch 118/500\n",
      "Epoch 119/500\n",
      "Epoch 120/500\n",
      "Epoch 121/500\n",
      "Epoch 122/500\n",
      "Epoch 123/500\n",
      "Epoch 124/500\n",
      "Epoch 125/500\n",
      "Epoch 126/500\n",
      "Epoch 127/500\n",
      "Epoch 128/500\n",
      "Epoch 129/500\n",
      "Epoch 130/500\n",
      "Epoch 131/500\n",
      "Epoch 132/500\n",
      "Epoch 133/500\n",
      "Epoch 134/500\n",
      "Epoch 135/500\n",
      "Epoch 136/500\n",
      "Epoch 137/500\n",
      "Epoch 138/500\n",
      "Epoch 139/500\n",
      "\n",
      "Epoch 139: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
      "Epoch 140/500\n",
      "Epoch 141/500\n",
      "Epoch 142/500\n",
      "Epoch 143/500\n",
      "Epoch 144/500\n",
      "Epoch 145/500\n",
      "Epoch 146/500\n",
      "Epoch 147/500\n",
      "Epoch 148/500\n",
      "Epoch 149/500\n",
      "Epoch 150/500\n",
      "Epoch 151/500\n",
      "Epoch 152/500\n",
      "Epoch 153/500\n",
      "Epoch 154/500\n",
      "Epoch 155/500\n",
      "Epoch 156/500\n",
      "Epoch 157/500\n",
      "Epoch 158/500\n",
      "Epoch 159/500\n",
      "Epoch 160/500\n",
      "Epoch 161/500\n",
      "Epoch 162/500\n",
      "Epoch 163/500\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 0.003164062276482582.\n",
      "Epoch 164/500\n",
      "Epoch 165/500\n",
      "Epoch 166/500\n",
      "Epoch 167/500\n",
      "Epoch 168/500\n",
      "Epoch 169/500\n",
      "Epoch 170/500\n",
      "Epoch 171/500\n",
      "Epoch 172/500\n",
      "Epoch 173/500\n",
      "\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 0.0023730467073619366.\n",
      "Epoch 174/500\n",
      "Epoch 175/500\n",
      "Epoch 176/500\n",
      "Epoch 177/500\n",
      "Restoring model weights from the end of the best epoch: 157.\n",
      "Epoch 177: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 24: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "Epoch 41/500\n",
      "Epoch 42/500\n",
      "Epoch 43/500\n",
      "Epoch 44/500\n",
      "Epoch 45/500\n",
      "Epoch 46/500\n",
      "Epoch 47/500\n",
      "Epoch 48/500\n",
      "Epoch 49/500\n",
      "Epoch 50/500\n",
      "Epoch 51/500\n",
      "Epoch 52/500\n",
      "Epoch 53/500\n",
      "Epoch 54/500\n",
      "Epoch 55/500\n",
      "Epoch 56/500\n",
      "Epoch 57/500\n",
      "Epoch 58/500\n",
      "Epoch 59/500\n",
      "Epoch 60/500\n",
      "Epoch 61/500\n",
      "Epoch 62/500\n",
      "Epoch 63/500\n",
      "Epoch 64/500\n",
      "Epoch 65/500\n",
      "Epoch 66/500\n",
      "Epoch 67/500\n",
      "Epoch 68/500\n",
      "Epoch 69/500\n",
      "Epoch 70/500\n",
      "Epoch 71/500\n",
      "Epoch 72/500\n",
      "Epoch 73/500\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 74/500\n",
      "Epoch 75/500\n",
      "Epoch 76/500\n",
      "Epoch 77/500\n",
      "Epoch 78/500\n",
      "Epoch 79/500\n",
      "Epoch 80/500\n",
      "Epoch 81/500\n",
      "Epoch 82/500\n",
      "Epoch 83/500\n",
      "Epoch 84/500\n",
      "Epoch 85/500\n",
      "Epoch 86/500\n",
      "Epoch 87/500\n",
      "Epoch 88/500\n",
      "Epoch 89/500\n",
      "Epoch 90/500\n",
      "Epoch 91/500\n",
      "Epoch 92/500\n",
      "Epoch 93/500\n",
      "Epoch 94/500\n",
      "Epoch 95/500\n",
      "Epoch 96/500\n",
      "Epoch 97/500\n",
      "Epoch 98/500\n",
      "Epoch 99/500\n",
      "Epoch 100/500\n",
      "Epoch 101/500\n",
      "Epoch 102/500\n",
      "Epoch 103/500\n",
      "Epoch 104/500\n",
      "Epoch 105/500\n",
      "Epoch 106/500\n",
      "Epoch 107/500\n",
      "Epoch 108/500\n",
      "Epoch 109/500\n",
      "Epoch 110/500\n",
      "Epoch 111/500\n",
      "Epoch 112/500\n",
      "Epoch 113/500\n",
      "Epoch 114/500\n",
      "Epoch 115/500\n",
      "Epoch 116/500\n",
      "Epoch 117/500\n",
      "Epoch 118/500\n",
      "Epoch 119/500\n",
      "Epoch 120/500\n",
      "Epoch 121/500\n",
      "Epoch 122/500\n",
      "Epoch 123/500\n",
      "Epoch 124/500\n",
      "Epoch 125/500\n",
      "Epoch 126/500\n",
      "Epoch 127/500\n",
      "Epoch 128/500\n",
      "Epoch 129/500\n",
      "Epoch 130/500\n",
      "Epoch 131/500\n",
      "Epoch 132/500\n",
      "Epoch 133/500\n",
      "Epoch 134/500\n",
      "Epoch 135/500\n",
      "Epoch 136/500\n",
      "\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 137/500\n",
      "Epoch 138/500\n",
      "Epoch 139/500\n",
      "Epoch 140/500\n",
      "Epoch 141/500\n",
      "Epoch 142/500\n",
      "Epoch 143/500\n",
      "Epoch 144/500\n",
      "Epoch 145/500\n",
      "Epoch 146/500\n",
      "\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
      "Epoch 147/500\n",
      "Epoch 148/500\n",
      "Epoch 149/500\n",
      "Epoch 150/500\n",
      "Epoch 151/500\n",
      "Epoch 152/500\n",
      "Restoring model weights from the end of the best epoch: 132.\n",
      "Epoch 152: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 26: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "Epoch 41/500\n",
      "Epoch 42/500\n",
      "Epoch 43/500\n",
      "Epoch 44/500\n",
      "Epoch 45/500\n",
      "Epoch 46/500\n",
      "Epoch 47/500\n",
      "Epoch 48/500\n",
      "Epoch 49/500\n",
      "Epoch 50/500\n",
      "Epoch 51/500\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 52/500\n",
      "Epoch 53/500\n",
      "Epoch 54/500\n",
      "Epoch 55/500\n",
      "Epoch 56/500\n",
      "Epoch 57/500\n",
      "Epoch 58/500\n",
      "Epoch 59/500\n",
      "Epoch 60/500\n",
      "Epoch 61/500\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
      "Epoch 61: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "Epoch 41/500\n",
      "Epoch 42/500\n",
      "Epoch 43/500\n",
      "Epoch 44/500\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 45/500\n",
      "Epoch 46/500\n",
      "Epoch 47/500\n",
      "Epoch 48/500\n",
      "Epoch 49/500\n",
      "Epoch 50/500\n",
      "Epoch 51/500\n",
      "Epoch 52/500\n",
      "Epoch 53/500\n",
      "Epoch 54/500\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 54: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 27: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 25: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 23: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
      "Epoch 35: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "Epoch 41/500\n",
      "Epoch 42/500\n",
      "Epoch 43/500\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 44/500\n",
      "Epoch 45/500\n",
      "Epoch 46/500\n",
      "Epoch 47/500\n",
      "Epoch 48/500\n",
      "Epoch 49/500\n",
      "Epoch 50/500\n",
      "Epoch 51/500\n",
      "Epoch 52/500\n",
      "Epoch 53/500\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
      "Epoch 53: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 37: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 34: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 28: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "Epoch 41/500\n",
      "Epoch 42/500\n",
      "Epoch 43/500\n",
      "Epoch 44/500\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
      "Epoch 44: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 40: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 40: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 27: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 22: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 41/500\n",
      "Epoch 42/500\n",
      "Epoch 43/500\n",
      "Epoch 44/500\n",
      "Epoch 45/500\n",
      "Epoch 46/500\n",
      "Epoch 47/500\n",
      "Epoch 48/500\n",
      "Epoch 49/500\n",
      "Epoch 50/500\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
      "Epoch 50: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 30: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 29: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 36: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 35: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "Epoch 41/500\n",
      "Epoch 42/500\n",
      "Epoch 43/500\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
      "Epoch 44/500\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Epoch 44: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "Epoch 41/500\n",
      "Epoch 42/500\n",
      "Epoch 43/500\n",
      "Epoch 44/500\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 45/500\n",
      "Epoch 46/500\n",
      "Epoch 47/500\n",
      "Epoch 48/500\n",
      "Epoch 49/500\n",
      "Epoch 50/500\n",
      "Epoch 51/500\n",
      "Epoch 52/500\n",
      "Epoch 53/500\n",
      "Epoch 54/500\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
      "Epoch 54: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 33: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 31: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 27: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 24: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 34: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Epoch 32/500\n",
      "Epoch 33/500\n",
      "Epoch 34/500\n",
      "Epoch 35/500\n",
      "Epoch 36/500\n",
      "Epoch 37/500\n",
      "Epoch 38/500\n",
      "Epoch 39/500\n",
      "Epoch 40/500\n",
      "Epoch 41/500\n",
      "Epoch 42/500\n",
      "Epoch 43/500\n",
      "Epoch 44/500\n",
      "Epoch 45/500\n",
      "Epoch 46/500\n",
      "Epoch 47/500\n",
      "Epoch 48/500\n",
      "Epoch 49/500\n",
      "Epoch 50/500\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 51/500\n",
      "Epoch 52/500\n",
      "Epoch 53/500\n",
      "Epoch 54/500\n",
      "Epoch 55/500\n",
      "Epoch 56/500\n",
      "Epoch 57/500\n",
      "Epoch 58/500\n",
      "Epoch 59/500\n",
      "Epoch 60/500\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 61/500\n",
      "Epoch 62/500\n",
      "Epoch 63/500\n",
      "Epoch 64/500\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Epoch 64: early stopping\n",
      "Epoch 1/500\n",
      "Epoch 2/500\n",
      "Epoch 3/500\n",
      "Epoch 4/500\n",
      "Epoch 5/500\n",
      "Epoch 6/500\n",
      "Epoch 7/500\n",
      "Epoch 8/500\n",
      "Epoch 9/500\n",
      "Epoch 10/500\n",
      "Epoch 11/500\n",
      "Epoch 12/500\n",
      "Epoch 13/500\n",
      "Epoch 14/500\n",
      "Epoch 15/500\n",
      "Epoch 16/500\n",
      "Epoch 17/500\n",
      "Epoch 18/500\n",
      "Epoch 19/500\n",
      "Epoch 20/500\n",
      "Epoch 21/500\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "Epoch 22/500\n",
      "Epoch 23/500\n",
      "Epoch 24/500\n",
      "Epoch 25/500\n",
      "Epoch 26/500\n",
      "Epoch 27/500\n",
      "Epoch 28/500\n",
      "Epoch 29/500\n",
      "Epoch 30/500\n",
      "Epoch 31/500\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "Epoch 31: early stopping\n"
     ]
    }
   ],
   "source": [
    "for cluster in clustered.keys():\n",
    "    cluster_df = pd.read_csv(\n",
    "        os.path.join(os.environ['PROCESSED_DATA_PATH'],\n",
    "                     f'processed_{cluster}.csv'))\n",
    "    train_df, test_df = split(df=cluster_df, train_split=train_split)\n",
    "    scaler, scaled_train_df = scale(df=train_df[features + [target]],\n",
    "                                    cluster=cluster,\n",
    "                                    timestamp=timestamp,\n",
    "                                    test=False)\n",
    "    _, scaled_test_df = scale(df=test_df[features + [target]],\n",
    "                              cluster=cluster,\n",
    "                              timestamp=timestamp,\n",
    "                              test=True)\n",
    "    model, val_metrics = train(df=scaled_train_df,\n",
    "                               target=target,\n",
    "                               cluster=cluster,\n",
    "                               folds=folds,\n",
    "                               lookback=seq_len,\n",
    "                               univariate=univariate,\n",
    "                               lstm_units=lstm_units,\n",
    "                               learning_rate=learning_rate,\n",
    "                               batch_size=batch_size,\n",
    "                               val_split=val_split,\n",
    "                               epochs=epochs,\n",
    "                               patience=patience,\n",
    "                               timestamp=timestamp,\n",
    "                               verbose=verbose)\n",
    "    with open(\n",
    "            os.path.join(os.environ['RUNS_PATH'], timestamp,\n",
    "                         f'cluster_{cluster}',\n",
    "                         f'val_metrics_cluster_{cluster}.json'), 'w') as fp:\n",
    "        json.dump(val_metrics, fp)\n",
    "    model.save(\n",
    "        os.path.join(os.environ['RUNS_PATH'], timestamp, f'cluster_{cluster}',\n",
    "                     f'cluster_{cluster}.h5'))\n",
    "    test_metrics = evaluate(df=scaled_test_df,\n",
    "                            model=model,\n",
    "                            lookback=seq_len,\n",
    "                            batch_size=batch_size,\n",
    "                            univariate=univariate,\n",
    "                            target=target,\n",
    "                            verbose=verbose)\n",
    "    with open(\n",
    "            os.path.join(os.environ['RUNS_PATH'], timestamp,\n",
    "                         f'cluster_{cluster}',\n",
    "                         f'test_metrics_cluster_{cluster}.json'), 'w') as fp:\n",
    "        json.dump(test_metrics, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
